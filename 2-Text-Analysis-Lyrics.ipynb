{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "[Free Form Description]\n",
    "\n",
    "**Resources**\n",
    "\n",
    "- [The NRC Valence, Arousal, and Dominance Lexicon](http://saifmohammad.com/WebPages/nrc-vad.html)\n",
    "- [Spotipy docs (Python Wrapper)](https://spotipy.readthedocs.io/en/latest/)\n",
    "\n",
    "\n",
    "**Data Input:**\n",
    "\n",
    "- `data/processed/audio_data.csv`: DataFrame of all CC tracks with \"Sonic Brutality Index\" (from notebook 1)\n",
    "- `data/raw/NRC-VAD-Lexicon.txt`: Data of approx 20'000 words with valence, arousal and dominance scores\n",
    "\n",
    "**Data Output:**\n",
    "\n",
    "- `...`: ...\n",
    "\n",
    "**Changes**\n",
    "\n",
    "- 2019-02-18: Start project\n",
    "- 20-02-25: Complete audio analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries, load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-20T21:27:45.612562Z",
     "start_time": "2020-01-20T21:27:45.472340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from pprint import pprint\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "# Visualization\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('raph-base')\n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the lexicon into a Pandas DataFrame requires a little tweaking / cleaning first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/NRC-VAD-Lexicon.txt') as file:\n",
    "    data_list = []\n",
    "    line = file.readline()\n",
    "    while line:\n",
    "        data_list.append(str(line))\n",
    "        line = file.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Word\\tValence\\tArousal\\tDominance\\n',\n",
       " 'aaaaaaah\\t0.479\\t0.606\\t0.291\\n',\n",
       " 'aaaah\\t0.520\\t0.636\\t0.282\\n',\n",
       " 'aardvark\\t0.427\\t0.490\\t0.437\\n',\n",
       " 'aback\\t0.385\\t0.407\\t0.288\\n']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check results\n",
    "data_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and clean\n",
    "data_list2 = [x.replace('\\n', '').split('\\t') for x in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vad_lexicon = pd.DataFrame(data_list2[1:], columns=data_list2[0], dtype=float)\n",
    "vad_lexicon.columns = (col.lower() for col in vad_lexicon.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>valence</th>\n",
       "      <th>arousal</th>\n",
       "      <th>dominance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>bloodshed</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word  valence  arousal  dominance\n",
       "1860  bloodshed    0.048    0.942      0.525"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check results ...\n",
    "display(vad_lexicon.iloc[[1860]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly what we are looking for: low valence, high arousal ... ;-) \n",
    "\n",
    "We can also see that `dominance` is quite neutral and probably no feature that will be of further help. To more easily filter and analize for words with a combination of low-valence and high-arousal I will create a new feature `anti-valence` that is (1 - valance). Then we can simply sum the 2 scores to get a `word brutality index (WBI)`. (To land in a range between 0 and 1 we will normalize it using sklearn's minmax_scaler.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = vad_lexicon.copy()\n",
    "lexicon['anti_valence'] = lexicon['valence'].apply(lambda x: 1-x)\n",
    "wbi = minmax_scale(lexicon['anti_valence'] + lexicon['arousal'])\n",
    "lexicon['wbi'] = wbi\n",
    "lexicon.drop(['valence', 'dominance'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>arousal</th>\n",
       "      <th>anti_valence</th>\n",
       "      <th>wbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8472</th>\n",
       "      <td>homicide</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11521</th>\n",
       "      <td>murderer</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.992746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9854</th>\n",
       "      <td>killer</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.981585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>abduction</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17277</th>\n",
       "      <td>suicidebombing</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.979353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11523</th>\n",
       "      <td>murderous</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.977679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4366</th>\n",
       "      <td>dangerous</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.976562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>assassinate</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.974888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>aggresive</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.971540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>bloodbath</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.970982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  arousal  anti_valence       wbi\n",
       "8472         homicide    0.973         0.990  1.000000\n",
       "11521        murderer    0.960         0.990  0.992746\n",
       "9854           killer    0.971         0.959  0.981585\n",
       "20          abduction    0.990         0.938  0.980469\n",
       "17277  suicidebombing    0.957         0.969  0.979353\n",
       "11523       murderous    0.940         0.983  0.977679\n",
       "4366        dangerous    0.941         0.980  0.976562\n",
       "1035      assassinate    0.969         0.949  0.974888\n",
       "386         aggresive    0.971         0.941  0.971540\n",
       "1856        bloodbath    0.971         0.940  0.970982"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>arousal</th>\n",
       "      <th>anti_valence</th>\n",
       "      <th>wbi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>zombie</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.704799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  arousal  anti_valence       wbi\n",
       "19999  zombie    0.648         0.786  0.704799"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check results ...\n",
    "display(lexicon.nlargest(10, 'wbi'))\n",
    "display(lexicon.loc[lexicon['word'] == 'zombie'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, people nowadays definitely seem to be more scared of suicide bombers than of zombies ... how come?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request data\n",
    "\n",
    "### Artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Artist URI\n",
    "\n",
    "name = \"Cannibal Corpse\"\n",
    "\n",
    "def get_artist_uri(name):\n",
    "    results = sp.search(q='artist:' + name, type='artist')\n",
    "    items = results['artists']['items']\n",
    "    artist_uri = items[0]['uri'] \n",
    "    return artist_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_uri = get_artist_uri(name)\n",
    "pprint(artist_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trackslist\n",
    "\n",
    "The easiest way to query for tracks is as follows:\n",
    "\n",
    "```python\n",
    "results = sp.search(q=artist, limit=50, type='track')\n",
    "for i, t in enumerate(results['tracks']['items']):\n",
    "    print(' ', i, t['name'])\n",
    "```\n",
    "\n",
    "But problem is that the upper limit possible is 50, and CC have released many more songs than that, so I will try a work around. Get a list of all albums, clean it a bit and then combine all the tracks of each single album in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Artist albums (dict)\n",
    "# Note: setting title as key catches some duplicates\n",
    "\n",
    "def get_artist_albums(artist_uri):\n",
    "    albums = {}\n",
    "    results = sp.artist_albums(artist_uri, album_type='album')\n",
    "    for i, item in enumerate(results['items']):\n",
    "        albums[item['name'].title()] = item['uri']\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_albums = get_artist_albums(artist_uri)\n",
    "pprint(artist_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually clean some entries, we want originals only and no live albums\n",
    "albums_to_delete = ['レッド・ビフォー・ブラック', \n",
    "                     'Vile (Expanded Edition)', \n",
    "                     'The Bleeding - Reissue',\n",
    "                     'Live Cannibalism',\n",
    "                     'Torturing And Eviscerating',\n",
    "                   ]\n",
    "def get_clean_album_uri_list(artist_albums, albums_to_delete=albums_to_delete):\n",
    "    if albums_to_delete is not None:\n",
    "        for key in albums_to_delete:\n",
    "            artist_albums.pop(key)  \n",
    "    artist_albums_uri = [uri for uri in artist_albums.values()]\n",
    "    return artist_albums_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_albums_uri = get_clean_album_uri_list(artist_albums, albums_to_delete)\n",
    "print(artist_albums_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_tracklist_dict(artist_albums_uri):\n",
    "    tracklist = {}\n",
    "    for album_uri in artist_albums_uri:\n",
    "        album = sp.album(album_uri)\n",
    "        for track in album['tracks']['items']:\n",
    "            tracklist[track['name'].title()] = track['uri']\n",
    "    return tracklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_tracklist = get_full_tracklist_dict(artist_albums_uri)\n",
    "print(list(full_tracklist.items())[0])\n",
    "print(\"Total tracks:\", len(full_tracklist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Features\n",
    "\n",
    "We use the audio features provided by spotify ([see here](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/)) to determine the sonic brutality of a track. We actually only need `Energy`and `Valence` for that, but in addition let's also have a look at the `Dancability`of Cannibal Corpse. Just for fun.\n",
    "\n",
    "> Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.\n",
    "    \n",
    "> Valence is a measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry). \n",
    "    \n",
    "> Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_features_dict(full_tracklist):\n",
    "    audio_features_dict = {}\n",
    "    for uri in list(full_tracklist.values()):\n",
    "        features = sp.audio_features(uri)\n",
    "        audio_features_dict[uri] = {'energy': features[0]['energy'],\n",
    "                                    'valence': features[0]['valence'],\n",
    "                                    'danceability': features[0]['danceability'],\n",
    "                                   }\n",
    "    return audio_features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features_dict = get_audio_features_dict(full_tracklist)\n",
    "pprint(list(audio_features_dict.items())[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Songs\n",
    "\n",
    "### Prepare dataframe\n",
    "\n",
    "Getting the songs and features in separate dicts was ok for exploring the Spotify API and Spotipy wrapper, but for our the actual Analyis I prefer to combine everything in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_df1 = pd.DataFrame(full_tracklist.items(), columns = ['title', 'uri'])\n",
    "temp_df2 = pd.DataFrame(audio_features_dict.items(), columns = ['uri', 'features'])\n",
    "assert len(temp_df1) == len(temp_df2)\n",
    "song_data = pd.merge(temp_df1, temp_df2, on=['uri'])\n",
    "display(song_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data['energy'] = song_data['uri'].apply(lambda x: audio_features_dict[x]['energy'])\n",
    "song_data['valence'] = song_data['uri'].apply(lambda x: audio_features_dict[x]['valence'])\n",
    "song_data['danceability'] = song_data['uri'].apply(lambda x: audio_features_dict[x]['danceability'])\n",
    "song_data.drop('features', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(song_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, sharex=True, figsize=(16,4))\n",
    "\n",
    "sns.distplot(song_data['energy'], ax=axes[0])\n",
    "sns.distplot(song_data['valence'], ax=axes[1])\n",
    "sns.distplot(song_data['danceability'],color=\"grey\", ax=axes[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outlier with energy value of approx. 0.8 only\n",
    "# And get link to a 30 sek sample\n",
    "\n",
    "low_energy_uri = song_data['uri'].loc[song_data['energy'] == song_data['energy'].min()].values[0]\n",
    "results = sp.track(low_energy_uri)\n",
    "print('track       : ' + results['name'])\n",
    "print('from ablbum : ' + results['album']['name'])\n",
    "print('audio       : ' + results['preview_url'])\n",
    "print('cover art   : ' + results['album']['images'][0]['url'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate \"Sonic Brutality Index\"\n",
    "\n",
    "Using both `energy` and `valence`, we can create an equation for the “Sonic Brutality Index” by calculating the geometric mean of `energy` and `1 - valence` (subtracting valence from 1 so that a higher value means it’s more “negative”). This way, the most brutal songs will be those that are both high in energy and low in valence, while equally weighting both.\n",
    "\n",
    "$$\\\\Sonic Brutality Index = \\sqrt{(1 - valence) * energy}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sbi(valence, energy):\n",
    "    sbi = np.sqrt((1 - valence) * energy)\n",
    "    return sbi\n",
    "    \n",
    "song_data['sbi'] = song_data.apply(lambda x: calc_sbi(x['valence'], x['energy']), axis=1)\n",
    "display(song_data.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.distplot(song_data['sbi'], bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for most brutal song (accustically)\n",
    "\n",
    "most_brutal_uri = song_data['uri'].loc[song_data['sbi'] == song_data['sbi'].max()].values[0]\n",
    "results = sp.track(most_brutal_uri)\n",
    "print('track       : ' + results['name'])\n",
    "print('from ablbum : ' + results['album']['name'])\n",
    "print('audio       : ' + results['preview_url'])\n",
    "print('cover art   : ' + results['album']['images'][0]['url'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube-Clip: \n",
    "\n",
    "<a href=\"http://www.youtube.com/watch?feature=player_embedded&v=57WwWg9PD74\n",
    "\" target=\"_blank\"><img src=\"http://img.youtube.com/vi/57WwWg9PD74/0.jpg\" \n",
    "alt=\"Link to Youtube clip\" width=\"240\" height=\"180\" border=\"10\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data.sort_values(['sbi'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets listen to a not so brutal but danceable track now\n",
    "# (don't expect too much though ...)\n",
    "\n",
    "rabid_uri = song_data['uri'].loc[song_data['title'] == 'Rabid'].values[0]\n",
    "results = sp.track(rabid_uri)\n",
    "print('track       : ' + results['name'])\n",
    "print('from ablbum : ' + results['album']['name'])\n",
    "print('audio       : ' + results['preview_url'])\n",
    "print('cover art   : ' + results['album']['images'][0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save data\n",
    "song_data.to_csv('data/processed/audio_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Compare Sonic Brutality of Cannibal Corpse and Cannabis Corpse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve data from API\n",
    "\n",
    "name2 = \"Cannabis Corpse\"\n",
    "\n",
    "artist_uri2 = get_artist_uri(name2)\n",
    "artist_albums2 = get_artist_albums(artist_uri2)\n",
    "artist_albums_uri2 = get_clean_album_uri_list(artist_albums2, albums_to_delete=None)\n",
    "full_tracklist2 = get_full_tracklist_dict(artist_albums_uri2)\n",
    "audio_features_dict2 = get_audio_features_dict(full_tracklist2)\n",
    "pprint(list(audio_features_dict2.items())[:2])\n",
    "print(\"\\nTotal Number of songs:\", len(audio_features_dict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct DataFrame\n",
    "\n",
    "temp_df1 = pd.DataFrame(full_tracklist2.items(), columns = ['title', 'uri'])\n",
    "temp_df2 = pd.DataFrame(audio_features_dict2.items(), columns = ['uri', 'features'])\n",
    "assert len(temp_df1) == len(temp_df2)\n",
    "song_data2 = pd.merge(temp_df1, temp_df2, on=['uri'])\n",
    "\n",
    "song_data2['energy'] = song_data2['uri'].apply(lambda x: audio_features_dict2[x]['energy'])\n",
    "song_data2['valence'] = song_data2['uri'].apply(lambda x: audio_features_dict2[x]['valence'])\n",
    "song_data2['danceability'] = song_data2['uri'].apply(lambda x: audio_features_dict2[x]['danceability'])\n",
    "song_data2.drop('features', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculae SBI\n",
    "\n",
    "song_data2['sbi'] = song_data2.apply(lambda x: calc_sbi(x['valence'], x['energy']), axis=1)\n",
    "display(song_data2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Brutality of Cannibal Corpse and Cannabis Corpse\n",
    "\n",
    "print(f\"Mean Brutality Score for {name}: {song_data['sbi'].mean():.2f}\")\n",
    "print(f\"Mean Brutality Score for {name2}: {song_data2['sbi'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "sns.distplot(song_data['sbi'], bins=20, label=name);\n",
    "sns.distplot(song_data2['sbi'], color='yellow', bins=20, label=name2);\n",
    "plt.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_brutal_uri2 = song_data2['uri'].loc[song_data2['sbi'] == song_data2['sbi'].max()].values[0]\n",
    "results = sp.track(most_brutal_uri2)\n",
    "print('track       : ' + results['name'])\n",
    "print('from ablbum : ' + results['album']['name'])\n",
    "print('audio       : ' + results['preview_url'])\n",
    "print('cover art   : ' + results['album']['images'][0]['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_data2.nlargest(1, 'sbi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "sounds",
   "language": "python",
   "name": "sounds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
